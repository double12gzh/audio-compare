"""
UI ç»„ä»¶æ¨¡å—
æä¾›å„ç§å¯å¤ç”¨çš„ç•Œé¢ç»„ä»¶
"""

import streamlit as st
import pandas as pd
from typing import Optional, Dict, Any, List
import plotly.graph_objects as go
import os
import librosa

from ..utils.config import AppConfig


class SidebarConfig:
    """ä¾§è¾¹æ é…ç½®ç»„ä»¶"""

    def __init__(self, config: AppConfig):
        self.config = config

    def render(self) -> Dict[str, Any]:
        """æ¸²æŸ“ä¾§è¾¹æ é…ç½®"""
        st.sidebar.header("âš™ï¸ é…ç½®å‚æ•°")

        # éŸ³é¢‘å‚æ•°è®¾ç½®
        st.sidebar.subheader("éŸ³é¢‘å‚æ•°")
        sample_rate = st.sidebar.selectbox(
            "é‡‡æ ·ç‡", [8000, 16000, 22050, 44100], index=2
        )

        n_mels = st.sidebar.slider("Mel æ»¤æ³¢å™¨ç»„æ•°é‡", 64, 256, 128)

        # æ›´æ–°é…ç½®
        self.config.audio.default_sample_rate = sample_rate
        self.config.audio.n_mels = n_mels

        return {"sample_rate": sample_rate, "n_mels": n_mels}


class AudioFileSelector:
    """éŸ³é¢‘æ–‡ä»¶é€‰æ‹©å™¨ç»„ä»¶ï¼ˆè‡ªåŠ¨æ‰«æç›®å½•ï¼‰"""

    def __init__(self, config: AppConfig):
        self.config = config
        self.audio_root = getattr(config, "audio_root", "./audio_files")
        self.supported_exts = tuple("." + ext for ext in config.file.supported_formats)

    def _scan_files(self):
        if not os.path.exists(self.audio_root):
            return []
        files = [
            f
            for f in os.listdir(self.audio_root)
            if os.path.isfile(os.path.join(self.audio_root, f))
            and f.lower().endswith(self.supported_exts)
        ]
        return sorted(files)

    def _get_audio_format(self, filename: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–éŸ³é¢‘æ ¼å¼"""
        ext = os.path.splitext(filename)[1].lower()
        format_map = {
            ".wav": "audio/wav",
            ".mp3": "audio/mp3",
            ".flac": "audio/flac",
            ".ogg": "audio/ogg",
            ".m4a": "audio/mp4",
        }
        return format_map.get(ext, "audio/wav")

    def _get_audio_info(self, audio_path: str) -> Dict[str, Any]:
        """è·å–éŸ³é¢‘æ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯"""
        try:
            # æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            file_size = os.path.getsize(audio_path)
            file_size_mb = file_size / (1024 * 1024)

            # éŸ³é¢‘ä¿¡æ¯
            y, sr = librosa.load(audio_path, sr=None)  # ä¸é‡é‡‡æ ·ï¼Œè·å–åŸå§‹é‡‡æ ·ç‡
            duration = len(y) / sr

            return {
                "file_size_mb": file_size_mb,
                "duration": duration,
                "sample_rate": sr,
                "channels": 1 if len(y.shape) == 1 else y.shape[1],
                "format": os.path.splitext(audio_path)[1].upper()[1:],  # å»æ‰ç‚¹å·
            }
        except Exception as e:
            return {
                "file_size_mb": os.path.getsize(audio_path) / (1024 * 1024),
                "duration": "N/A",
                "sample_rate": "N/A",
                "channels": "N/A",
                "format": os.path.splitext(audio_path)[1].upper()[1:],
            }

    def _render_audio_details(
        self, audio_path: str, filename: str, key_prefix: str = ""
    ):
        """æ¸²æŸ“éŸ³é¢‘è¯¦ç»†ä¿¡æ¯ï¼ˆå¯æŠ˜å ï¼‰"""
        with st.expander(f"ğŸ“‹ {filename} è¯¦ç»†ä¿¡æ¯", expanded=False):
            info = self._get_audio_info(audio_path)

            # ä½¿ç”¨æ›´å°çš„å­—å·æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            st.markdown(f"**æ–‡ä»¶å¤§å°:** {info['file_size_mb']:.2f} MB")
            if info["duration"] != "N/A":
                st.markdown(f"**æ—¶é•¿:** {info['duration']:.2f} ç§’")
            else:
                st.markdown("**æ—¶é•¿:** N/A")
            if info["sample_rate"] != "N/A":
                st.markdown(f"**é‡‡æ ·ç‡:** {info['sample_rate']} Hz")
            else:
                st.markdown("**é‡‡æ ·ç‡:** N/A")
            st.markdown(f"**æ ¼å¼:** {info['format']}")

            # æ˜¾ç¤ºé€šé“ä¿¡æ¯
            if info["channels"] != "N/A":
                channels_text = (
                    "å•å£°é“" if info["channels"] == 1 else f'{info["channels"]} å£°é“'
                )
                st.markdown(f"**éŸ³é¢‘é€šé“:** {channels_text}")

    def render_single(self, key: str = "single_audio_file") -> str:
        files = self._scan_files()
        if not files:
            st.warning(f"ç›®å½• {self.audio_root} ä¸‹æ²¡æœ‰å¯ç”¨éŸ³é¢‘æ–‡ä»¶")
            return None
        selected = st.selectbox("é€‰æ‹©éŸ³é¢‘æ–‡ä»¶", files, key=key)
        if selected:
            audio_path = os.path.join(self.audio_root, selected)
            # æ˜¾ç¤ºéŸ³é¢‘æ’­æ”¾å™¨
            audio_format = self._get_audio_format(selected)
            st.audio(audio_path, format=audio_format)
            # æ˜¾ç¤ºéŸ³é¢‘è¯¦ç»†ä¿¡æ¯
            self._render_audio_details(audio_path, selected, key)
            return audio_path
        return None

    def render_dual(
        self, key1: str = "audio1_file", key2: str = "audio2_file"
    ) -> tuple:
        files = self._scan_files()
        if not files:
            st.warning(f"ç›®å½• {self.audio_root} ä¸‹æ²¡æœ‰å¯ç”¨éŸ³é¢‘æ–‡ä»¶")
            return None, None
        col1, col2 = st.columns(2)
        with col1:
            audio1 = st.selectbox("é€‰æ‹©ç¬¬ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶", files, key=key1)
            if audio1:
                audio_path1 = os.path.join(self.audio_root, audio1)
                audio_format1 = self._get_audio_format(audio1)
                st.audio(audio_path1, format=audio_format1)
                # æ˜¾ç¤ºéŸ³é¢‘è¯¦ç»†ä¿¡æ¯
                self._render_audio_details(audio_path1, audio1, key1)
        with col2:
            audio2 = st.selectbox("é€‰æ‹©ç¬¬äºŒä¸ªéŸ³é¢‘æ–‡ä»¶", files, key=key2)
            if audio2:
                audio_path2 = os.path.join(self.audio_root, audio2)
                audio_format2 = self._get_audio_format(audio2)
                st.audio(audio_path2, format=audio_format2)
                # æ˜¾ç¤ºéŸ³é¢‘è¯¦ç»†ä¿¡æ¯
                self._render_audio_details(audio_path2, audio2, key2)
        path1 = os.path.join(self.audio_root, audio1) if audio1 else None
        path2 = os.path.join(self.audio_root, audio2) if audio2 else None
        return path1, path2

    def render_batch(self, key: str = "batch_audio_files") -> list:
        files = self._scan_files()
        if not files:
            st.warning(f"ç›®å½• {self.audio_root} ä¸‹æ²¡æœ‰å¯ç”¨éŸ³é¢‘æ–‡ä»¶")
            return []
        selected = st.multiselect("é€‰æ‹©å¤šä¸ªéŸ³é¢‘æ–‡ä»¶", files, key=key)
        if selected:
            st.subheader("éŸ³é¢‘è¯•å¬")
            # ä¸ºæ¯ä¸ªé€‰ä¸­çš„æ–‡ä»¶æ˜¾ç¤ºæ’­æ”¾å™¨
            for i, file in enumerate(selected):
                audio_path = os.path.join(self.audio_root, file)
                audio_format = self._get_audio_format(file)
                st.write(f"**{file}**")
                st.audio(audio_path, format=audio_format)
                # æ˜¾ç¤ºéŸ³é¢‘è¯¦ç»†ä¿¡æ¯
                self._render_audio_details(audio_path, file, f"{key}_{i}")
                if i < len(selected) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªæ–‡ä»¶æ—¶æ·»åŠ åˆ†éš”çº¿
                    st.divider()
        return [os.path.join(self.audio_root, f) for f in selected]


class AudioInfoDisplay:
    """éŸ³é¢‘ä¿¡æ¯æ˜¾ç¤ºç»„ä»¶"""

    @staticmethod
    def render_metrics(audio_info: Dict[str, Any]):
        """æ¸²æŸ“éŸ³é¢‘æŒ‡æ ‡"""
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("æ—¶é•¿", f"{audio_info.get('duration', 0):.2f}ç§’")
        with col2:
            st.metric("é‡‡æ ·ç‡", f"{audio_info.get('sample_rate', 0)}Hz")
        with col3:
            st.metric("RMS", f"{audio_info.get('rms', 0):.4f}")
        with col4:
            st.metric("é›¶äº¤å‰ç‡", f"{audio_info.get('zero_crossing_rate', 0):.4f}")

    @staticmethod
    def render_features_table(features: Dict[str, Any]):
        """æ¸²æŸ“ç‰¹å¾è¡¨æ ¼"""
        if not features:
            return

        feature_df = pd.DataFrame(
            [
                ["æ—¶é•¿", f"{features.get('duration', 0):.2f}ç§’"],
                ["RMS", f"{features.get('rms', 0):.4f}"],
                ["é›¶äº¤å‰ç‡", f"{features.get('zero_crossing_rate', 0):.4f}"],
                ["é¢‘è°±è´¨å¿ƒ", f"{features.get('spectral_centroid', 0):.2f}Hz"],
                ["é¢‘è°±å¸¦å®½", f"{features.get('spectral_bandwidth', 0):.2f}Hz"],
                ["é¢‘è°±æ»šé™", f"{features.get('spectral_rolloff', 0):.2f}Hz"],
            ],
            columns=["ç‰¹å¾", "å€¼"],
        )

        st.dataframe(feature_df, use_container_width=True)


class SimilarityDisplay:
    """ç›¸ä¼¼åº¦æ˜¾ç¤ºç»„ä»¶"""

    @staticmethod
    def render_metrics(similarity: Dict[str, float]):
        """æ¸²æŸ“ç›¸ä¼¼åº¦æŒ‡æ ‡"""
        if not similarity:
            return

        col1, col2, col3, col4, col5 = st.columns(5)

        with col1:
            st.metric("ç›¸å…³ç³»æ•°", f"{similarity.get('correlation', 0):.4f}")
        with col2:
            st.metric("å‡æ–¹è¯¯å·®", f"{similarity.get('mse', 0):.6f}")
        with col3:
            snr_value = similarity.get("snr", 0)
            if snr_value == float("inf"):
                st.metric("ä¿¡å™ªæ¯”", "âˆ")
            else:
                st.metric("ä¿¡å™ªæ¯”", f"{snr_value:.2f}dB")
        with col4:
            st.metric("ä½™å¼¦ç›¸ä¼¼åº¦", f"{similarity.get('cosine_similarity', 0):.4f}")
        with col5:
            st.metric("MFCCç›¸ä¼¼åº¦", f"{similarity.get('mfcc_similarity', 0):.4f}")

        # æ˜¾ç¤ºå¯¹æ¯”é‡‡æ ·ç‡ä¿¡æ¯
        if "comparison_sr" in similarity:
            st.info(f"å¯¹æ¯”é‡‡æ ·ç‡: {similarity['comparison_sr']} Hz")


class ChartDisplay:
    """å›¾è¡¨æ˜¾ç¤ºç»„ä»¶"""

    @staticmethod
    def render_chart(fig: Optional[go.Figure], title: str = ""):
        """æ¸²æŸ“å›¾è¡¨"""
        if fig is not None:
            # ä¼˜åŒ–å›¾ä¾‹é…ç½®ï¼Œé¿å…è¦†ç›–
            fig.update_layout(
                legend=dict(
                    orientation="h",  # æ°´å¹³å›¾ä¾‹
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1,
                    bgcolor="rgba(255,255,255,0.8)",  # åŠé€æ˜èƒŒæ™¯
                    bordercolor="rgba(0,0,0,0.1)",
                    borderwidth=1,
                ),
                margin=dict(t=80, b=40, l=40, r=40),  # å¢åŠ é¡¶éƒ¨è¾¹è·ç»™å›¾ä¾‹
            )
            if title:
                st.subheader(title)
            st.plotly_chart(
                fig, use_container_width=True, config={"displayModeBar": False}
            )

    @staticmethod
    def render_charts(charts: List[tuple]):
        """æ¸²æŸ“å¤šä¸ªå›¾è¡¨"""
        for title, fig in charts:
            ChartDisplay.render_chart(fig, title)


class BatchResultsDisplay:
    """æ‰¹é‡ç»“æœæ˜¾ç¤ºç»„ä»¶"""

    @staticmethod
    def render_table(results: List[Dict[str, Any]]):
        """æ¸²æŸ“ç»“æœè¡¨æ ¼"""
        if not results:
            st.warning("æ²¡æœ‰å¯æ˜¾ç¤ºçš„ç»“æœ")
            return

        df = pd.DataFrame(results)
        st.dataframe(df, use_container_width=True)

    @staticmethod
    def render_export_button(
        results: List[Dict[str, Any]], filename: str = "audio_analysis_results.csv"
    ):
        """æ¸²æŸ“å¯¼å‡ºæŒ‰é’®"""
        if not results:
            return

        df = pd.DataFrame(results)
        csv = df.to_csv(index=False)

        st.download_button(
            label="ä¸‹è½½åˆ†æç»“æœ (CSV)", data=csv, file_name=filename, mime="text/csv"
        )


class CSSStyler:
    """CSS æ ·å¼ç»„ä»¶"""

    @staticmethod
    def inject_css():
        """æ³¨å…¥è‡ªå®šä¹‰CSSæ ·å¼"""
        st.markdown(
            """
        <style>
            .main-header {
                font-size: 2.5rem;
                color: #1f77b4;
                text-align: center;
                margin-bottom: 2rem;
            }
            .metric-card {
                background-color: #f0f2f6;
                padding: 1rem;
                border-radius: 0.5rem;
                margin: 0.5rem 0;
            }
            .upload-section {
                border: 2px dashed #ccc;
                border-radius: 10px;
                padding: 2rem;
                text-align: center;
                margin: 1rem 0;
            }
            .info-box {
                background-color: #e8f4fd;
                border-left: 4px solid #1f77b4;
                padding: 1rem;
                margin: 1rem 0;
                border-radius: 0 5px 5px 0;
            }
            .warning-box {
                background-color: #fff3cd;
                border-left: 4px solid #ffc107;
                padding: 1rem;
                margin: 1rem 0;
                border-radius: 0 5px 5px 0;
            }
            .error-box {
                background-color: #f8d7da;
                border-left: 4px solid #dc3545;
                padding: 1rem;
                margin: 1rem 0;
                border-radius: 0 5px 5px 0;
            }
        </style>
        """,
            unsafe_allow_html=True,
        )

    @staticmethod
    def info_box(message: str):
        """æ˜¾ç¤ºä¿¡æ¯æ¡†"""
        st.markdown(f'<div class="info-box">{message}</div>', unsafe_allow_html=True)

    @staticmethod
    def warning_box(message: str):
        """æ˜¾ç¤ºè­¦å‘Šæ¡†"""
        st.markdown(f'<div class="warning-box">{message}</div>', unsafe_allow_html=True)

    @staticmethod
    def error_box(message: str):
        """æ˜¾ç¤ºé”™è¯¯æ¡†"""
        st.markdown(f'<div class="error-box">{message}</div>', unsafe_allow_html=True)
